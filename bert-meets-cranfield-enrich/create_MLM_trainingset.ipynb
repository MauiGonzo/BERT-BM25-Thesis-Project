{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"create_MLM_trainingset.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"environment":{"name":"common-cu110.m79","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cu110:m79"},"kernelspec":{"display_name":"Python [conda env:root] *","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4e9f6c25d664416794b43f89e8473fe4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d754cbc2f35343cabfd2ead4deadc2c3","IPY_MODEL_bce33db3d3cc4e0dbd87c14f018d1041","IPY_MODEL_c89933eb801b49b2880d28721432073d"],"layout":"IPY_MODEL_56e590a7146343f98658704fc0397565"}},"56e590a7146343f98658704fc0397565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d754cbc2f35343cabfd2ead4deadc2c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14d99db090e34428bbe09745b02d3a41","placeholder":"​","style":"IPY_MODEL_522552bef3ae4fecbafdc5ec88202ba0","value":"Epoch 0: 100%"}},"bce33db3d3cc4e0dbd87c14f018d1041":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efd041e7c6dd4b54b75387f8bf14ef2a","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8a779e78f894802849516254b43f1f3","value":63}},"c89933eb801b49b2880d28721432073d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4707a8284af94b6cba032cb366b5d8f8","placeholder":"​","style":"IPY_MODEL_81f85a0a564141dcb3495512af400761","value":" 63/63 [00:56&lt;00:00,  1.28it/s, loss=0.368]"}},"522552bef3ae4fecbafdc5ec88202ba0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14d99db090e34428bbe09745b02d3a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8a779e78f894802849516254b43f1f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efd041e7c6dd4b54b75387f8bf14ef2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81f85a0a564141dcb3495512af400761":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4707a8284af94b6cba032cb366b5d8f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"035df59d2361433fb1fe559f5adefa55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32c2040133a14b9082a5f75783fac2c6","IPY_MODEL_95a19cf023c54395a95ad64fc4dfadf1","IPY_MODEL_69b88705dcf64ea9b144e5424ab74a91"],"layout":"IPY_MODEL_aac4906d22034d1a91614d4b50f88ca1"}},"aac4906d22034d1a91614d4b50f88ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32c2040133a14b9082a5f75783fac2c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c55ff4e2480d4065b1d1602a82a1e069","placeholder":"​","style":"IPY_MODEL_7fa8526510a04d149c414ac1572365fe","value":"Epoch 1: 100%"}},"95a19cf023c54395a95ad64fc4dfadf1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9a7b845159d4b49b1685544d0c79b7a","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f5682c362244f95b6d02af027c73678","value":63}},"69b88705dcf64ea9b144e5424ab74a91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d9775189c02492cb774c2951723bad7","placeholder":"​","style":"IPY_MODEL_27b97a0168754a8abfe0062a31868c0d","value":" 63/63 [00:56&lt;00:00,  1.28it/s, loss=0.216]"}},"7fa8526510a04d149c414ac1572365fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c55ff4e2480d4065b1d1602a82a1e069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f5682c362244f95b6d02af027c73678":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9a7b845159d4b49b1685544d0c79b7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27b97a0168754a8abfe0062a31868c0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d9775189c02492cb774c2951723bad7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123943c563ae49e5aba55edc20a6d86e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef263ccad1d34e4f93f0769391dcbfc8","IPY_MODEL_475e493e58174b82a206d5348b583f40","IPY_MODEL_745663bbdb634688bac395170bbbb928"],"layout":"IPY_MODEL_9683b726f1f14589abdda6fb48dd4cbb"}},"9683b726f1f14589abdda6fb48dd4cbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef263ccad1d34e4f93f0769391dcbfc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b2e36a1ff8d4d36968740d441c4add0","placeholder":"​","style":"IPY_MODEL_ab64ed99ba84423980510637e1170a0d","value":"Epoch 2: 100%"}},"475e493e58174b82a206d5348b583f40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_abb7bcd3dafa45d9abce9ce42ef20158","max":63,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e31666f3c0df4190b5f3f28b81f558d1","value":63}},"745663bbdb634688bac395170bbbb928":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6198284a605f45a089eadd692fde99c0","placeholder":"​","style":"IPY_MODEL_be94586e4fbe421fa41ede69c6ca037e","value":" 63/63 [00:56&lt;00:00,  1.28it/s, loss=0.206]"}},"ab64ed99ba84423980510637e1170a0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2e36a1ff8d4d36968740d441c4add0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e31666f3c0df4190b5f3f28b81f558d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abb7bcd3dafa45d9abce9ce42ef20158":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be94586e4fbe421fa41ede69c6ca037e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6198284a605f45a089eadd692fde99c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5650a706e64b4bdf8c9c71bd6a1c5de7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d2efe5ac64e42548910a2f294ebdeff","IPY_MODEL_27a9d737f85c49ec8d3960b7e02c6b3d","IPY_MODEL_1655301491e743bf86e4e6b16b65c5e2"],"layout":"IPY_MODEL_1e1fb965d0f541599c908c393f41ef96"}},"1e1fb965d0f541599c908c393f41ef96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d2efe5ac64e42548910a2f294ebdeff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddea83214a9f4f6f8b3d5f8fc1611920","placeholder":"​","style":"IPY_MODEL_4583eb9164d74063892bc3cfd7e74ad0","value":"100%"}},"27a9d737f85c49ec8d3960b7e02c6b3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d685b4b32094b37985fcc2bc34c9071","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95d5a7bbe2be47899f2efdfe69baff49","value":25}},"1655301491e743bf86e4e6b16b65c5e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_529eb6d6bc23401082b281d886834346","placeholder":"​","style":"IPY_MODEL_6065f57054324a0f9388ccd4ef593a60","value":" 25/25 [00:08&lt;00:00,  3.15it/s]"}},"4583eb9164d74063892bc3cfd7e74ad0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddea83214a9f4f6f8b3d5f8fc1611920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95d5a7bbe2be47899f2efdfe69baff49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d685b4b32094b37985fcc2bc34c9071":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6065f57054324a0f9388ccd4ef593a60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"529eb6d6bc23401082b281d886834346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"g1JZPM2O7jwW"},"source":["# Finetuning BERT for the MLM-task with the Cranfield set\n","generic MLM training inspired by [this post](https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c) by James Brigg\n","\n"," The following notebook creates a MLM-training set eand trains a pre-trained BERT model for the MLM task, finaly is saves the model in de Models dir."]},{"cell_type":"markdown","metadata":{"id":"GNi0z-T28QO9"},"source":["## Import Depenedencies, do Setting"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hEsWidHX8KfX","executionInfo":{"elapsed":862,"status":"ok","timestamp":1632122787112,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"f6e51292-bf79-44ef-f7d7-445a2574ee3f"},"source":["# the next line requires that this notebook is connected to google drive\n","# %cd /content/drive/MyDrive/COMPUTING SCIENCE/THESIS_PROJECT/bert-meets-cranfield/Code\n","%cd /home/jupyter/BERT-BM25-Thesis-Project/bert-meets-cranfield-enrich/Code"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["/home/jupyter/BERT-BM25-Thesis-Project/bert-meets-cranfield-enrich/Code\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PKkEFLx8d4E","executionInfo":{"elapsed":8553,"status":"ok","timestamp":1632122797108,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"1a367c94-8d37-4692-bf69-9347de6a2ff6"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.10.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.8.28)\n","Requirement already satisfied: huggingface-hub>=0.0.12 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.17)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.2)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (5.4.1)\n","Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.0.12->transformers) (3.10.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\n","Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n"]}]},{"cell_type":"code","metadata":{"id":"k63D-Jek8jtG"},"source":["from transformers import BertTokenizer, BertForMaskedLM\n","# from pytorch_pretrained_bert import WEIGHTS_NAME, CONFIG_NAME\n","import torch\n","import torch.nn as nn\n","# import os\n","\n","import data_utils\n","\n","from transformers import AdamW\n","from tqdm import tqdm, tqdm_notebook, notebook\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JJyKfW288m6B"},"source":["# Set Hyperparameters and Flags"]},{"cell_type":"code","metadata":{"id":"gwZA9-Hk9TBE"},"source":["output_dir = \"/home/jupyter/BERT-BM25-Thesis-Project/Models/\" #@param {type:\"string\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lBEnPKjm8mAP","executionInfo":{"elapsed":183,"status":"ok","timestamp":1632124479169,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"6cd0ce8e-ffcd-4b23-85d1-2e75b7a81e5f"},"source":["MAX_LENGTH = 128\n","BATCH_SIZE = 16\n","LEARNING_RATE = 5e-5\n","EPOCHS = 2\n","\n","# GLOBAL TESING FLAG\n","ALLOW_CONSECUTIVE_MASKING= False\n","\n","# model_dir = '/content/drive/MyDrive/COMPUTING SCIENCE/THESIS_PROJECT/bert-meets-cranfield/Models/'\n","# custom\n","output_model_file = output_dir + 'BERT_Cranfield_MLM_model-' + str(MAX_LENGTH) + '-' + str(BATCH_SIZE) + '-' + str(LEARNING_RATE) + '-' + str(EPOCHS) + '.bin'\n","output_config_file = output_dir + 'BERT_Cranfield_MLM_config-' + str(MAX_LENGTH) + '-' + str(BATCH_SIZE) + '-' + str(LEARNING_RATE) + '-' +  str(EPOCHS) + '.bin'\n","output_vocab_file = output_dir + 'BERT_Cranfield_MLM_vocab-' + str(MAX_LENGTH) + '-' + str(BATCH_SIZE) + '-' + str(LEARNING_RATE) + '-' +  str(EPOCHS) + '.bin'\n","\n","print(\"# =========MLM=TRAINING===============================\")\n","print(\"#               Hyper-Parameters\")\n","print(LEARNING_RATE)\n","print(MAX_LENGTH)\n","print(BATCH_SIZE)\n","print(EPOCHS)\n","print(\"#               Experiment-Settings\")\n","print('ALLOW_CONSECUTIVE_MASKING ', ALLOW_CONSECUTIVE_MASKING)\n","\n","print(\"#               Other\")\n","print(torch.cuda.get_device_name())\n","print(\"# ========================================\")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["# =========MLM=TRAINING===============================\n","#               Hyper-Parameters\n","5e-05\n","128\n","16\n","2\n","#               Experiment-Settings\n","ALLOW_CONSECUTIVE_MASKING  False\n","#               Other\n","Tesla T4\n","# ========================================\n"]}]},{"cell_type":"markdown","metadata":{"id":"MVVPlpWt2SAb"},"source":["## Get tokenized corpus\n","This cells inmport the Cranfield corpus and tokenize it. They also add labels for the training and testing."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21MK5a0x2Lf7","executionInfo":{"elapsed":2999,"status":"ok","timestamp":1632124519256,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"ac43a5ce-b93f-400c-dc9a-c43b10ecd48b"},"source":["corpus = data_utils.get_corpus('../Data/cran/cran.all.1400')\n","# create tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","# do_lower_case: lowercase the input when tokenizing\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","metadata":{"id":"QZEh-tdw2sKr"},"source":["inputs = tokenizer(corpus, return_tensors='pt', max_length=MAX_LENGTH, \n","                   truncation=True, padding='max_length')\n","# inputs has no labels yet, so we create them by copy the input_ids\n","inputs['labels'] = inputs.input_ids.detach().clone()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fnY7FIOL21GG"},"source":["# Masking the training set\n","basic task is mask a certain percentage, around 15%, while not masksing the special tokens. Based on ongoing insights there is a function that can prevent the maksing of consecutive tokens."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WAZqJ1pA22xe","executionInfo":{"elapsed":326,"status":"ok","timestamp":1632124526034,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"65864f5b-aa70-49ec-c3e9-949acec81b70"},"source":["torch.random.manual_seed(234)\n","if ALLOW_CONSECUTIVE_MASKING:\n","  # maks at random using thresholded random values \n","  rand = torch.rand(inputs.input_ids.shape)\n","  # create the masking array, note that certain tokens are off limits\n","  mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n","            (inputs.input_ids != 102) * (inputs.input_ids != 0)\n","elif not ALLOW_CONSECUTIVE_MASKING:\n","  # omit the use of even or oneven indices\n","  basis = [False, True]\n","  chessboard = np.tile(basis, inputs.input_ids.shape )\n","  # reshape\n","  chessboard = chessboard[:, 0:MAX_LENGTH]\n","  chessboard[:,-1] = False\n","  chessboard = torch.tensor(chessboard)\n","  # rand around 0.3 should be best, but ginven the fixed seed, we can work toward the result.\n","  rand_chessboard = ( rand < .35 ) * chessboard\n","  mask_arr = ( rand_chessboard) * (inputs.input_ids != 101) * \\\n","            (inputs.input_ids != 102) * (inputs.input_ids != 0) \n","  print(mask_arr[0])\n","  # check how masked\n","  print(sum(mask_arr[0] == True) /128)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([False, False, False,  True, False, False, False,  True, False, False,\n","        False,  True, False, False, False, False, False, False, False,  True,\n","        False, False, False,  True, False,  True, False, False, False, False,\n","        False, False, False, False, False, False, False, False, False,  True,\n","        False, False, False,  True, False,  True, False, False, False, False,\n","        False, False, False, False, False, False, False,  True, False,  True,\n","        False,  True, False,  True, False, False, False, False, False, False,\n","        False,  True, False, False, False, False, False, False, False,  True,\n","        False, False, False, False, False, False, False, False, False,  True,\n","        False, False, False, False, False, False, False, False, False, False,\n","        False, False, False, False, False, False, False, False, False,  True,\n","        False, False, False, False, False, False, False, False, False, False,\n","        False,  True, False, False, False, False, False, False])\n","tensor(0.1406)\n"]}]},{"cell_type":"markdown","metadata":{"id":"WDOZYon53jS5"},"source":["test to check the sets we've just build"]},{"cell_type":"code","metadata":{"id":"iVfuYTJm3rMq"},"source":["selection = []\n","\n","for i in range(inputs.input_ids.shape[0]):\n","  selection.append(\n","      torch.flatten(mask_arr[i].nonzero()).tolist()\n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0FDyHHYW38Pf"},"source":["The random chosen `input_ids` are to be overwitten with the mask character 103"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C49KstY_4Voh","executionInfo":{"elapsed":26,"status":"ok","timestamp":1632124526035,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"56e65a54-772b-44c3-b1bc-663584034884"},"source":["for i in range(inputs.input_ids.shape[0]):\n","  inputs.input_ids[i, selection[i]] = 103\n","# testing:\n","inputs.input_ids"],"execution_count":null,"outputs":[{"data":{"text/plain":["tensor([[  101,  6388,  4812,  ...,  4297, 28578,   102],\n","        [  101,   103, 18330,  ...,   103,  6895,   102],\n","        [  101,  1996,  6192,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  9211,  1997,  ...,   103,  2011,   102],\n","        [  101, 10131,  2989,  ...,     0,     0,     0],\n","        [  101,   103, 10131,  ...,     0,     0,     0]])"]},"execution_count":183,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171},"id":"yGABwkrM4g_6","executionInfo":{"elapsed":33,"status":"ok","timestamp":1632124526045,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"88d33d67-cdba-47a5-c3de-233473a86380"},"source":["# make an illustration\n","input0 = inputs.input_ids[0]\n","tokenizer.decode(input0)"],"execution_count":null,"outputs":[{"data":{"text/plain":["'[CLS] experimental investigation [MASK] the aerodynamics [MASK] a wing in [MASK] slipstream an experimental study of a [MASK] in a propeller [MASK]tream [MASK] made in order to determine the spanwise distribution of the lift increase [MASK] to slipstream [MASK] different [MASK] of attack of the wing and at different free stream to [MASK]tream [MASK] ratios [MASK] results [MASK] intended in part as an evaluation basis [MASK] different theoretical treatments of this problem the [MASK] span loading curves, together with supporting evidence, [MASK] that a substantial part of the lift increment produced by the slipstream was due to a [MASK] destalling / or boundary - layer - control effect [MASK] integrated remaining lift increm [SEP]'"]},"execution_count":184,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"ShQyn1C44keh"},"source":["Here the consequtive masking can be seen (if they are there - we made a flag that prevents such behaviour)"]},{"cell_type":"markdown","metadata":{"id":"JfE9SAaz485B"},"source":["### Create dataloader\n","customized PyTorch DataLoader as it is to be used when training"]},{"cell_type":"code","metadata":{"id":"eOK8WHs05Dds"},"source":["class CranfieldDataset(torch.utils.data.Dataset):\n","  def __init__(self, encodings):\n","    self.encodings = encodings\n","  def __getitem__(self, idx):\n","    return{key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","  def __len__(self):\n","    return len(self.encodings.input_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xaryx45G5GFz"},"source":["# initialize the data\n","dataset = CranfieldDataset(inputs)\n","# split the input in train and test\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [1000, 400], generator=torch.Generator().manual_seed(88))\n","# and initialize the dataloader\n","# keep the settings\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-NYbgxYb5MFF"},"source":["# Set up training / evalutation\n","* set the device to GPU if it is there\n","* intialize the optimizer"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0oRIdsp5PiL","executionInfo":{"elapsed":295,"status":"ok","timestamp":1632124528710,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"1c7ceafc-7dc5-4dcc-ef41-df82a88b49f1"},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","if torch.cuda.is_available():\n"," print('GPU Type:', torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["GPU Type: Tesla T4\n"]}]},{"cell_type":"code","metadata":{"id":"WrmBtok45VGb"},"source":["# capture\n","model.to(device)\n","# activate model\n","model.train()\n","torch.cuda\n","optim = AdamW(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjtYFVMJ5iXN","executionInfo":{"elapsed":255,"status":"ok","timestamp":1632124530441,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"b5ac1622-efda-4f10-e697-8ad2819f644f"},"source":["# check input keys\n","inputs.keys()"],"execution_count":null,"outputs":[{"data":{"text/plain":["dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"]},"execution_count":189,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"K_GRSq9g5mmy"},"source":["# Train / Test"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218,"referenced_widgets":["4e9f6c25d664416794b43f89e8473fe4","56e590a7146343f98658704fc0397565","d754cbc2f35343cabfd2ead4deadc2c3","bce33db3d3cc4e0dbd87c14f018d1041","c89933eb801b49b2880d28721432073d","522552bef3ae4fecbafdc5ec88202ba0","14d99db090e34428bbe09745b02d3a41","d8a779e78f894802849516254b43f1f3","efd041e7c6dd4b54b75387f8bf14ef2a","81f85a0a564141dcb3495512af400761","4707a8284af94b6cba032cb366b5d8f8","035df59d2361433fb1fe559f5adefa55","aac4906d22034d1a91614d4b50f88ca1","32c2040133a14b9082a5f75783fac2c6","95a19cf023c54395a95ad64fc4dfadf1","69b88705dcf64ea9b144e5424ab74a91","7fa8526510a04d149c414ac1572365fe","c55ff4e2480d4065b1d1602a82a1e069","7f5682c362244f95b6d02af027c73678","f9a7b845159d4b49b1685544d0c79b7a","27b97a0168754a8abfe0062a31868c0d","5d9775189c02492cb774c2951723bad7","123943c563ae49e5aba55edc20a6d86e","9683b726f1f14589abdda6fb48dd4cbb","ef263ccad1d34e4f93f0769391dcbfc8","475e493e58174b82a206d5348b583f40","745663bbdb634688bac395170bbbb928","ab64ed99ba84423980510637e1170a0d","2b2e36a1ff8d4d36968740d441c4add0","e31666f3c0df4190b5f3f28b81f558d1","abb7bcd3dafa45d9abce9ce42ef20158","be94586e4fbe421fa41ede69c6ca037e","6198284a605f45a089eadd692fde99c0","7741dee1057a45e58f43b6e956f21486","96a85a187c7f4b9aadb34b8319fdeec1"]},"id":"7pjs5YBN5zMv","executionInfo":{"elapsed":169764,"status":"ok","timestamp":1632124702210,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"5dc0831a-3665-46da-f54c-4d768cbd9c46"},"source":["for epoch in range(EPOCHS):\n","  loop = tqdm_notebook(train_loader, leave=True)\n","  for batch in loop:\n","    optim.zero_grad()\n","    # define input tensors\n","    input_ids       = batch['input_ids'].to(device)\n","    attention_mask  = batch['attention_mask'].to(device)\n","    labels          = batch['labels'].to(device)\n","    # process\n","    output = model(input_ids, attention_mask=attention_mask, labels=labels)\n","    loss = output.loss\n","    loss.backward()\n","    # update parameters\n","    optim.step()\n","    # print relevant info to progress bar\n","    loop.set_description(f'Epoch {epoch}')\n","    loop.set_postfix(loss=loss.item())"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7741dee1057a45e58f43b6e956f21486","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/63 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96a85a187c7f4b9aadb34b8319fdeec1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/63 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}]},{"cell_type":"markdown","metadata":{"id":"xUN8KSQN6llv"},"source":["## Save trained model\n","The following describes the technical implications and solutions found. It takes the PyTorch approach, since the method was implemented in this module. One could also choose to use the Tensorflow implementation, with potential benefit of integration with Googles Tensor Flow Processing Unit (TPU).\n","In both cases (MLM and NSP) the model was saved using the PyTorch function `state_dict`, this is because the BertModel used is a PyTorch `torch.nn.Module`  subclass, an elaborate description can be found on the [huggingface.co] website(https://huggingface.co/transformers/model_doc/bert.html\\#bertmodel). \n","A PyTorch model can be saved in something called a `state_dict`, this is a 'Python dictionary object that maps each layer to its parameter tensor', more can be read in the [maual](https://pytorch.org/tutorials/beginner/saving\\_loading\\_models.html\\#what-is-a-state-dict). \n","This enables easy inspection and selection of keys, this way only the encoder can be saved i.e. the keys starting with `bert.encoder` are filtered.\n","\n","Now, for the ranking a standard pre-trained BertModel is loaded, with on top of it a `BertForSequenceClassification`-task head, hereafter the encoder-parameters from either the MLM-task or the NSP-task are loaded. Following this two options will be researched, in one the encoder parameters will be frozen, in the other no parameters will be frozen. With these options the BERT re-ranker is trained with various settings, such as number of epochs and learning rate."]},{"cell_type":"code","metadata":{"id":"ZSzW-Yi76jGh","outputId":"377e797e-1155-49fb-8660-310ab74a4d98"},"source":["# next line takes care of potentially distributed /paralell training\n","# common practice on huggingface fora (Thom Wolf posts)\n","model_to_save = model.module if hasattr(model, 'module') else model\n","to_save_dict = model_to_save.state_dict()\n","to_save_with_prefix= {}\n","for key, value in to_save_dict.items():\n","    if key.startswith('bert.encoder'):\n","      to_save_with_prefix[key] = value\n","    # to_save_with_prefix['bert.encoder' + key] = value\n","    # print(key)\n","torch.save(to_save_with_prefix, output_model_file)\n","print(\"saved to: \", output_model_file)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["saved to:  /home/jupyter/BERT-BM25-Thesis-Project/Models/BERT_Cranfield_MLM_model-128-16-5e-05-2.bin\n"]}]},{"cell_type":"markdown","metadata":{"id":"-E3vdTXw7RtL"},"source":["Inspect the state dict, it should only contain parameters for the encoder"]},{"cell_type":"code","metadata":{"id":"_OHc9ytz7XTW","outputId":"98a6b388-e4c2-4083-99c9-88a90fe088f0"},"source":["# Check the state_dict \n","# for the MLM-task it would look like this\n","print(\"MLM-Models state dict:\\n\")\n","for param_tensor in to_save_with_prefix:\n","  print(param_tensor, \"\\t\", to_save_with_prefix[param_tensor].size())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["MLM-Models state dict:\n","\n","bert.encoder.layer.0.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.0.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.0.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.0.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.0.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.0.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.0.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.0.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.0.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.0.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.0.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.0.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.0.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.0.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.0.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.0.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.1.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.1.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.1.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.1.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.1.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.1.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.1.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.1.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.1.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.1.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.1.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.1.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.1.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.1.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.1.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.1.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.2.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.2.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.2.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.2.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.2.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.2.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.2.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.2.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.2.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.2.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.2.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.2.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.2.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.2.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.2.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.2.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.3.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.3.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.3.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.3.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.3.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.3.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.3.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.3.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.3.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.3.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.3.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.3.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.3.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.3.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.3.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.3.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.4.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.4.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.4.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.4.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.4.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.4.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.4.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.4.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.4.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.4.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.4.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.4.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.4.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.4.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.4.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.4.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.5.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.5.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.5.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.5.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.5.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.5.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.5.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.5.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.5.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.5.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.5.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.5.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.5.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.5.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.5.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.5.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.6.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.6.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.6.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.6.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.6.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.6.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.6.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.6.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.6.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.6.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.6.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.6.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.6.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.6.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.6.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.6.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.7.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.7.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.7.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.7.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.7.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.7.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.7.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.7.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.7.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.7.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.7.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.7.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.7.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.7.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.7.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.7.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.8.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.8.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.8.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.8.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.8.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.8.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.8.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.8.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.8.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.8.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.8.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.8.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.8.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.8.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.8.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.8.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.9.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.9.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.9.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.9.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.9.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.9.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.9.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.9.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.9.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.9.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.9.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.9.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.9.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.9.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.9.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.9.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.10.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.10.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.10.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.10.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.10.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.10.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.10.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.10.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.10.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.10.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.10.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.10.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.10.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.10.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.10.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.10.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.11.attention.self.query.weight \t torch.Size([768, 768])\n","bert.encoder.layer.11.attention.self.query.bias \t torch.Size([768])\n","bert.encoder.layer.11.attention.self.key.weight \t torch.Size([768, 768])\n","bert.encoder.layer.11.attention.self.key.bias \t torch.Size([768])\n","bert.encoder.layer.11.attention.self.value.weight \t torch.Size([768, 768])\n","bert.encoder.layer.11.attention.self.value.bias \t torch.Size([768])\n","bert.encoder.layer.11.attention.output.dense.weight \t torch.Size([768, 768])\n","bert.encoder.layer.11.attention.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.11.attention.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.11.attention.output.LayerNorm.bias \t torch.Size([768])\n","bert.encoder.layer.11.intermediate.dense.weight \t torch.Size([3072, 768])\n","bert.encoder.layer.11.intermediate.dense.bias \t torch.Size([3072])\n","bert.encoder.layer.11.output.dense.weight \t torch.Size([768, 3072])\n","bert.encoder.layer.11.output.dense.bias \t torch.Size([768])\n","bert.encoder.layer.11.output.LayerNorm.weight \t torch.Size([768])\n","bert.encoder.layer.11.output.LayerNorm.bias \t torch.Size([768])\n"]}]},{"cell_type":"markdown","metadata":{"id":"44vzw4-W7gMO"},"source":["# Evaluate MLM training\n","the accuracy is measured simply as the percentage correct predicted."]},{"cell_type":"code","metadata":{"id":"vi_9yHDN7fsf"},"source":["def acc(predictions, input_ids, labels, batch_size):\n","  # returns the accuracy i.e. correctly predicted fraction\n","  # predictions     [MaskedLMOutput]\n","  # input_ids       [torchTensor at device]\n","  # labels          [torchTensor at device]\n","  # batch_size      [int]\n","\n","  batch_accuracy = 0\n","  for bi in range(batch_size):\n","    # predictions per 'document'\n","    pbi = torch.argmax(predictions.logits[bi], dim=1)\n","    pbi = pbi.to('cpu').numpy()\n","    # get ground truth i.e. labels\n","    gt = labels[bi].to('cpu').numpy()\n","    # get nr of masked items\n","    mk = input_ids[bi].to('cpu').numpy()\n","    masked = np.sum(mk == 103)\n","    # get the difference between the predictions and the labels\n","    missed = np.setdiff1d(gt, pbi, assume_unique=True)\n","    # batch_accuracy += ((masked - len(missed) / masked) / batch_size)\n","    # print('missed: ', missed)\n","    # print('masked: ', masked)\n","    # print('batch_size: ', batch_size)\n","\n","    batch_accuracy += ( (1- (len(missed) / masked) ) / batch_size)\n","  return batch_accuracy "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5650a706e64b4bdf8c9c71bd6a1c5de7","1e1fb965d0f541599c908c393f41ef96","8d2efe5ac64e42548910a2f294ebdeff","27a9d737f85c49ec8d3960b7e02c6b3d","1655301491e743bf86e4e6b16b65c5e2","4583eb9164d74063892bc3cfd7e74ad0","ddea83214a9f4f6f8b3d5f8fc1611920","95d5a7bbe2be47899f2efdfe69baff49","0d685b4b32094b37985fcc2bc34c9071","6065f57054324a0f9388ccd4ef593a60","529eb6d6bc23401082b281d886834346","954dcfc272974940b5e7dc81a04cd1f8"]},"id":"V9St6XeZ77nl","executionInfo":{"elapsed":8158,"status":"ok","timestamp":1632124743309,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"1c70ea96-7587-4384-cae8-db98f8ca7d13"},"source":["model.eval()\n","sum_loss = 0\n","total_acc = 0\n","count = 0\n","loop = tqdm_notebook(test_loader, leave=True)\n","for batch in loop:\n","  with torch.no_grad():\n","    optim.zero_grad()\n","    input_ids       = batch['input_ids'].to(device)\n","    attention_mask  = batch['attention_mask'].to(device)\n","    labels          = batch['labels'].to(device)\n","    if input_ids.shape[0] is not BATCH_SIZE:\n","      break\n","    print('input_ids shape ', input_ids.shape)\n","    output = model(input_ids, attention_mask=attention_mask, labels=labels)\n","    # calculate the accuracy\n","    # predictions = output.logits\n","    batch_acc = acc(output, input_ids, labels, BATCH_SIZE)\n","    total_acc += batch_acc\n","    print('Batch accuracy: ', batch_acc, ' for batch ', count)\n","    \n","    sum_loss += output.loss.item()\n","    count += 1\n","print(sum_loss / count)\n","print(output.loss.item())\n","print('batch_acc :', total_acc / count)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  \"\"\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"954dcfc272974940b5e7dc81a04cd1f8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"name":"stdout","output_type":"stream","text":["input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.6653903388278388  for batch  0\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7343068351609205  for batch  1\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7467894142894141  for batch  2\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7956691167122838  for batch  3\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7277105231359042  for batch  4\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7962176270644877  for batch  5\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7044602283839982  for batch  6\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7585587546984606  for batch  7\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7800759809412555  for batch  8\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7121062551525937  for batch  9\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7093934235272112  for batch  10\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7324886685967141  for batch  11\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.765511160591252  for batch  12\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7472390124084498  for batch  13\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7012211866198935  for batch  14\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7504029978465047  for batch  15\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7784094927915054  for batch  16\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7115802072323811  for batch  17\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7417194250108337  for batch  18\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7518783973613021  for batch  19\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7427522846323641  for batch  20\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.6780275858400858  for batch  21\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7506306139740002  for batch  22\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7143906955450358  for batch  23\n","input_ids shape  torch.Size([16, 128])\n","Batch accuracy:  0.7316044471188166  for batch  24\n","0.3188127446174622\n","0.2542955279350281\n","batch_acc : 0.7371413869385403\n"]}]},{"cell_type":"code","metadata":{"id":"NiMj8Tqy_PCN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zdxmHKTp8VFd"},"source":["# Analysis"]},{"cell_type":"code","metadata":{"id":"Lz6tLo_7ppz0"},"source":["### illustrative analysis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":412},"id":"x4Ua3Gks-mhc","executionInfo":{"elapsed":25,"status":"ok","timestamp":1622541745701,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"943c584f-b587-4d04-9bab-67c0fe1c1b88"},"source":["# what is the item 0 of the test dataset\n","test0 = test_dataset[0]\n","print(test0['input_ids'])\n","a = np.array(test0['input_ids'])\n","# check te decoded version\n","tokenizer.decode(a)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([  101,  1996,  4895,   103,  2100,  6336,  1997,  1037,  3358,   103,\n","        10713,   103,  6463,   103, 25647,   103,  1011,  6336,  4972,   103,\n","         4777,  1997, 10713,   103,  6463,  2031,  2042, 10174,  2011,   103,\n","         2075,  1996, 28033,  1999,  8743,   103,  1998,  1996,  6466,   103,\n","         2886,  1997,  1996, 10709,  3358,  1996, 16268,  2024,  2241,  2006,\n","         1996,   103,  4118,   103,  3225,  6336,  1997,  1996, 10713,  3358,\n","         2003,  2179,  2000,   103,  2069,   103,  2625,  2084,  2008,  1997,\n","         1996,   103,  3358,  1010,  6168,  1996,  2345,  6336,  2089,   103,\n","         9839,  2625,  1996,  3399,  7127,  2008,  1996,  3988,  4353,  1997,\n","         6336,  2003,  2714,   103,  1996,   103,  4353, 10543,  4760,   103,\n","         8386,   103,  6336,  2044,  1037,  5573,  3131,  2689,  1999,   103,\n","         1997,  2886,  1010,   103, 20015,  1997,  1037, 22147, 11818, 26903,\n","         1010,  1998,  2076,  1037,  7142,  9808,  6895,   102])\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] the un [MASK]y lift of a wing [MASK] finite [MASK] ratio [MASK]stead [MASK] - lift functions [MASK] wings of finite [MASK] ratio have been calculated by [MASK]ing the aerodynamic inert [MASK] and the angle [MASK] attack of the infinite wing the calculations are based on the [MASK] method [MASK] starting lift of the finite wing is found to [MASK] only [MASK] less than that of the [MASK] wing, whereas the final lift may [MASK] considerably less the theory indicates that the initial distribution of lift is similar [MASK] the [MASK] distribution curves showing [MASK] variation [MASK] lift after a sudden unit change in [MASK] of attack, [MASK] penetration of a sharpedge gust, and during a continuous osci [SEP]'"]},"execution_count":35,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxYnPrv0Gp6L","executionInfo":{"elapsed":32,"status":"ok","timestamp":1622541746431,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"3bddd8f5-9889-4e2e-9599-51a59b4e0498"},"source":["test01 = test_dataset[0:2]\n","print(test01['input_ids'].size())"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 128])\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \"\"\"\n"]}]},{"cell_type":"code","metadata":{"id":"CLQd2xjDBGXA"},"source":["model.eval()\n","with torch.no_grad():\n","  input_ids       = test01['input_ids'].to(device)\n","  attention_mask  = test01['attention_mask'].to(device)\n","  predictions= model(input_ids, attention_mask=attention_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"E5UDVhp6D1nE","executionInfo":{"elapsed":36,"status":"ok","timestamp":1622541746439,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"713079d0-8caa-4a8c-db1c-f2cb7481fb33"},"source":["predictions.logits[0].size()\n","\n","# predicted_index = torch.argmax(predictions.logits[0], dim=0).item()\n","p0 = torch.argmax(predictions.logits[0], dim=1)\n","np0 = p0.to('cpu').numpy()\n","\n","# p0np = np.array(p0)\n","tokenizer.decode(np0)\n"],"execution_count":null,"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] the unsteady lift of a wing of finite aspect ratio unsteady - lift functions for wings of finite aspect ratio have been calculated by neglecting the aerodynamic inertia and the angle of attack of the infinite wing the calculations are based on the classical method the starting lift of the finite wing is found to be only slightly less than that of the finite wing, whereas the final lift may be considerably less the theory indicates that the initial distribution of lift is similar to the initial distribution curves showing the variation in lift after a sudden unit change in angle of attack, the penetration of a sharpedge gust, and during a continuous osci [SEP]'"]},"execution_count":38,"metadata":{"tags":[]},"output_type":"execute_result"}]},{"cell_type":"markdown","metadata":{"id":"G00oHL1WXaoJ"},"source":["Which should have been ([MASK]s partly made bold):\n","__NOTE__ the bold words are only correct when the CONESECUTIVE MASKING flag is up (note that for completeness, after this cell the label is given)\n","\n","\"the __unstead__y lift of a wing __of__ finite aspect ratio __.\n","unsteady__-lift functions __for__ wings of finite __aspect__ ratio have been\n","calculated by __correct__ing the aerodynamic inert __ia__ and the angle of __attack__ of\n"," the infinite wing . the __calculations__ are based on the operational\n","method .\n","the starting lift of the finite wing is found to be only slightly less\n","than that of the infinite wing,. whereas the final lift may be\n","considerably less . the theory indicates that the initial distribution of\n","lift is similar to the final distribution .\n","curves showing the variation of lift after a sudden unit change in angle\n"," of attack, during penetration of a sharpedge gust, and during a\n","continuous oscillation \""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwLzfreQK12h","executionInfo":{"elapsed":35,"status":"ok","timestamp":1622541746440,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"1e352c20-6186-482b-e121-9d2cf9e893e6"},"source":["print(tokenizer.decode(test01['labels'][0]))"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] the unsteady lift of a wing of finite aspect ratio unsteady - lift functions for wings of finite aspect ratio have been calculated by correcting the aerodynamic inertia and the angle of attack of the infinite wing the calculations are based on the operational method the starting lift of the finite wing is found to be only slightly less than that of the infinite wing, whereas the final lift may be considerably less the theory indicates that the initial distribution of lift is similar to the final distribution curves showing the variation of lift after a sudden unit change in angle of attack, during penetration of a sharpedge gust, and during a continuous osci [SEP]\n"]}]},{"cell_type":"markdown","metadata":{"id":"0eReuimepvST"},"source":["This illustration gives a good idea how the model 'works' and performs, but how good is it in terms of the confusion matrix?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgE7NP8jX2zw","executionInfo":{"elapsed":32,"status":"ok","timestamp":1622541746441,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"},"user_tz":-120},"outputId":"1a3cae6e-6913-4362-9d85-90b2f0f4562c"},"source":["# get the ground truth and prediction tokens, for this example\n","gt = test0['labels']\n","mk = test0['input_ids']\n","mk = mk.to('cpu').numpy()\n","pr = torch.argmax(predictions.logits[0], dim=1)\n","pr = pr.to('cpu').numpy()\n","\n","masked = np.sum(mk == 103)\n","missed = np.setdiff1d(gt, pr, assume_unique=True)\n","\n","print('masked: ', masked)\n","print('missed: ', missed) # token ids\n","perc = (masked - len(missed)) / masked\n","print('percentage guessed right: ', perc)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["masked:  22\n","missed:  [6149 6515]\n","percentage guessed right:  0.9090909090909091\n"]}]}]}