{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"multi-label-training-custom-models-added.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"environment":{"name":"common-cu110.m79","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cu110:m79"},"kernelspec":{"display_name":"Python [conda env:root] *","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-t_ZMd4LeXgL"},"source":["# BERT Meets Cranfield - Multilabel Training Approach\n","The dataset has been labeled with multiple labels indicating how relevant a certain document is. The Cranfield description explains it as follows:\n","1.  References which are a complete answer to the question.\n","\n","2.  References of a high degree of relevance, the lack of which either would have made the research impracticable or would have resulted in a considerable amount of extra work.\n","\n","3.  References which were useful, either as general background to the work or as suggesting methods of tackling certain aspects of the work.\n","\n","4.  References of minimum interest, for example, those that have been included from an historical viewpoint.\n","\n","5.  References of no interest. The following notebooks implements a functions that research wether and what method could make beneficial use of this relevance labeling.  \n","\n","*NOTE: Not all changes are in the notebook, a number of changes can be found in the `utils.py`*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fss4AAPjsdc2","executionInfo":{"status":"ok","timestamp":1632839139135,"user_tz":-120,"elapsed":302,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}},"outputId":"5f5fe43d-cdb3-4b67-fc35-48d4e70932cf"},"source":["%cd /content/drive/MyDrive/COMPUTING SCIENCE/THESIS_PROJECT/BERT-BM25-Thesis-Project/bert-meets-cranfield-multilabel/Code\n","# %cd /home/jupyter/BERT-BM25-Thesis-Project/bert-meets-cranfield-multilabel/Code"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/COMPUTING SCIENCE/THESIS_PROJECT/BERT-BM25-Thesis-Project/bert-meets-cranfield-multilabel/Code\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4xg0ZyG2bqH","executionInfo":{"status":"ok","timestamp":1632839139439,"user_tz":-120,"elapsed":15,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}},"outputId":"34d423bb-017f-4beb-894f-351ba42d47ad"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRlcr2u0fL5q","executionInfo":{"status":"ok","timestamp":1632839142987,"user_tz":-120,"elapsed":3561,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}},"outputId":"b86fe35f-3e5a-491b-9650-475399c26d6b"},"source":["!pip3 install -r ../requirements.txt"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy>=1.19.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 2)) (1.7.1)\n","Requirement already satisfied: rank_bm25>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 3)) (0.2.1)\n","Requirement already satisfied: transformers>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 4)) (4.11.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from -r ../requirements.txt (line 5)) (1.9.0+cu102)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (0.10.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (4.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (2019.12.20)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (21.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (5.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (4.62.2)\n","Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (0.0.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=3.1.0->-r ../requirements.txt (line 4)) (0.0.46)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->-r ../requirements.txt (line 5)) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.1.0->-r ../requirements.txt (line 4)) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.1.0->-r ../requirements.txt (line 4)) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.1.0->-r ../requirements.txt (line 4)) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.1.0->-r ../requirements.txt (line 4)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.1.0->-r ../requirements.txt (line 4)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=3.1.0->-r ../requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.1.0->-r ../requirements.txt (line 4)) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.1.0->-r ../requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.1.0->-r ../requirements.txt (line 4)) (1.15.0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"gVLKhUhufNbM"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"mOM6kY43fQ7U","executionInfo":{"status":"ok","timestamp":1632839146264,"user_tz":-120,"elapsed":3282,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":["import utils\n","import data_utils\n","from operator import itemgetter\n","import os\n","import numpy as np\n","\n","import torch\n","import importlib\n","# from transformers import BertForSequenceClassification, BertTokenizer, BertForMaskedLM, BertForNextSentencePrediction\n","from transformers import BertForSequenceClassification\n","\n","import timeit"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DRuHYyUifVsk"},"source":["### Import Refresh\n","When a supporting py-file (such as utils.py) is changed, this code will have the lib reloaded while not reloading the entire notebook."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wDay4M8afTKL","executionInfo":{"status":"ok","timestamp":1632839146268,"user_tz":-120,"elapsed":37,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}},"outputId":"8dd22c97-e9a4-485f-c6b5-2c66cebd5b55"},"source":["# call after making any changes in utils.py\n","importlib.reload(utils) \n","importlib.reload(data_utils)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'data_utils' from '/content/drive/My Drive/COMPUTING SCIENCE/THESIS_PROJECT/BERT-BM25-Thesis-Project/bert-meets-cranfield-multilabel/Code/data_utils.py'>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"mznu8BEmf2ds"},"source":["## Set hyper-paramters and test settings"]},{"cell_type":"code","metadata":{"id":"ai5fO45Wf1qT","executionInfo":{"status":"ok","timestamp":1632839146269,"user_tz":-120,"elapsed":33,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":["# ========================================\n","#               Hyper-Parameters\n","# ========================================\n","SEED = 76\n","MODE = 'Re-ranker'\n","MODEL_TYPE = 'bert-base-uncased'\n","LEARNING_RATE = 2e-5\n","MAX_LENGTH = 128\n","BATCH_SIZE = 32\n","EPOCHS = 1\n","TOP_BM25 = 100\n","MAP_CUT = 100\n","NDCG_CUT = 20\n","if MODE == 'Full-ranker':\n","    TEST_BATCH_SIZE = 1400\n","else:\n","    TEST_BATCH_SIZE = 100\n","\n","# Set the seed value all over the place to make this reproducible.\n","utils.initialize_random_generators(SEED)\n","\n","BM25_ENRICH = 'default' # or 'add' or 'swap' (default=no enrichment of BM25 results)\n","MULTI_LABEL = True\n","PER_LABEL_TESTING = False # if True, arg_max must be False\n","'''\n","  PER_LABEL_TESTING calculates the performance per predicted label. Contratry to\n","  the binary case, each relevance levels 0-5 has a prediction. Method can be\n","  seen as an alternative for the arg-max method. This flag is later implemented,\n","  therefore it will mess up the adminstration for the calculation of final NDCG.\n","  To circumvent this, the NDCG found for each fold, for each label has to be averaged.\n","'''\n","ARG_MAX_SORTING = True # if True, PER_LABEL_TESTING must be False\n","CUSTOM_MODEL = 'weighted-BCEWIthLogitsLoss' # default is None, utils.py explains\n","\n","LOAD_CUSTOM_TRAINED_MODEL = False #"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ll05QrP3Qac7","executionInfo":{"status":"ok","timestamp":1632839146269,"user_tz":-120,"elapsed":32,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":["models_dir = \"/home/jupyter/BERT-BM25-Thesis-Project/Models/\" #@param {type:\"string\"}\n","custom_model_name = \"BERT_Cranfield_MLM_model-128-16-5e-05-2.bin\" #@param {type:\"string\"}\n","\n","custom_model_path = models_dir + custom_model_name "],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kpy2-0MM0T26"},"source":["### Enriching function for BM25 results"]},{"cell_type":"code","metadata":{"id":"zstVSGg60T26","executionInfo":{"status":"ok","timestamp":1632839146270,"user_tz":-120,"elapsed":32,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":["def get_bm25_plus_other_rel(bm25_tn, labels, queries):\n","      bm25_top_n_rel_padded = [0]*len(queries) # a bm25_top_n list padded with the remaining relevant documents\n","      bm25_top_n_swap = [0]*len(queries) \n","    \n","      for qi in range(len(queries)):\n","        # get the list of relelvant documents\n","        lbi = np.where(labels[qi] == 1)\n","        # note this numbering is only compatible with the labels list\n","\n","\n","        # get the list of bm25_top_n\n","        np_bm25_qi_docs = np.array(bm25_top_n[qi]) \n","\n","        # evaluate what relevant documents should be added\n","        pad_rel = np.setdiff1d(lbi, np_bm25_qi_docs)\n","        # if len(pad_rel) > 0:\n","        pad_rel = tuple(pad_rel)\n","        bm25_top_n_rel_padded[qi] = bm25_top_n[qi] + pad_rel\n","        # create a list with least relevant items swapped for unfound relevant\n","        for i in range(len(pad_rel)):\n","          # CHECK\n","          # are we to swap a relevant document?\n","          current_doc = np_bm25_qi_docs[-(i+1)] \n","          \n","          if np.count_nonzero(current_doc == lbi) > 0:\n","            print('Relevant doc overwritten!')\n","          # CONTINUE  \n","          np_bm25_qi_docs[-(i+1)] = pad_rel[i]\n","          \n","        bm25_top_n_swap[qi] = np_bm25_qi_docs\n","      return bm25_top_n_rel_padded, bm25_top_n_swap"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2HLOroQocl_9"},"source":["### Function for loading custom model\n","Load in fact an encoder, that is trained with a specific specification"]},{"cell_type":"code","metadata":{"id":"8ULE9E5zdFen","executionInfo":{"status":"ok","timestamp":1632839146270,"user_tz":-120,"elapsed":32,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":["def load_specific_encoder(model_path):\n","  '''\n","    function to load saved encoder paramters\n","\n","    use this function to start every fold with a fresh model\n","  '''\n","  model = BertForSequenceClassification.from_pretrained(\n","        MODEL_TYPE,\n","        num_labels=2,\n","        output_attentions=False,\n","        output_hidden_states=False,\n","    )\n","  model.cuda\n","  print('LOAD : ', model_path )\n","\n","  # =======================\n","  # NOTE WHAT MODEL IS USED\n","  model.load_state_dict(torch.load(model_path), strict=False)\n","  # now you get a warning that extra training is required\n","\n","  if DO_FREEZING:\n","    print('FREEZING: set requires_grad to False')\n","    # freeze the encoder parameters (credits thomwolf of Huggingface)\n","    # for param in model.bert.encoder.parameters():\n","    #   param.requires_grad = False\n","\n","    # other method\n","    model.bert.encoder.requires_grad_(False)\n","  return model"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7og1VnHhgcsL"},"source":["## Train and Test"]},{"cell_type":"code","metadata":{"id":"3jAyQHGhgbFH","executionInfo":{"status":"ok","timestamp":1632839146501,"user_tz":-120,"elapsed":262,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":["# if __name__ == \"__main__\":\n","def train_test():\n","    print(\"# ========================================\")\n","    print(\"#               Hyper-Parameters\")\n","    print(MODE)\n","    print(MODEL_TYPE)\n","    print(LEARNING_RATE)\n","    print(MAX_LENGTH)\n","    print(BATCH_SIZE)\n","    print(EPOCHS)\n","    print(\"# ========================================\")\n","    print(\"#               Experiment-Settings\")\n","    print('BM25_ENRICHMENT:   ', BM25_ENRICH)\n","    print('MULTI_LABEL:       ', MULTI_LABEL)\n","    print('ARGMAX-SORTING:    ', ARG_MAX_SORTING)\n","    print('PER_LABEL_TESTING: ', PER_LABEL_TESTING)\n","    print('CUSTOM_MODEL:      ', CUSTOM_MODEL)\n","\n","\n","    print(\"# ========================================\")\n","    print(\"#               Other\")\n","    print(torch.cuda.get_device_name())\n","    print(\"# ========================================\")\n","    \n","    start = timeit.default_timer()\n","    \n","    device = utils.get_gpu_device()\n","    if not os.path.exists('../Output_Folder'):\n","        os.makedirs('../Output_Folder')\n","\n","    queries = data_utils.get_queries('../Data/cran/cran.qry')\n","    corpus = data_utils.get_corpus('../Data/cran/cran.all.1400')\n","    rel_fed = data_utils.get_judgments('../Data/cran/cranqrel')\n","\n","    labels = utils.get_binary_labels(rel_fed, multilabel=MULTI_LABEL)\n","    tokenized_corpus = [doc.split(\" \") for doc in corpus]\n","    tokenized_queries = [query.split(\" \") for query in queries]\n","\n","    bm25, bm25_top_n = utils.get_bm25_top_results(tokenized_corpus, tokenized_queries, TOP_BM25)\n","\n","    # no matter what BM25_ENRICH is, this line is needed to get `temp_feedback` for the test set\n","    padded_all, attention_mask_all, token_type_ids_all, temp_feedback = utils.bert_tokenizer(MODE, bm25_top_n, corpus,\n","                                                                                             labels, queries,\n","                                                                                             MAX_LENGTH, MODEL_TYPE)\n","    if BM25_ENRICH == 'swap':\n","        bm25_top_n_ext, bm25_top_n_swap = get_bm25_plus_other_rel(bm25_top_n, labels, queries)\n","        padded_all_swap, attention_mask_all_swap, token_type_ids_all_swap, temp_feedback_swap = utils.bert_tokenizer(MODE, bm25_top_n_swap, corpus,\n","                                                                                                                     labels, queries,\n","                                                                                                                     MAX_LENGTH, MODEL_TYPE)\n","    elif BM25_ENRICH == 'add':\n","        bm25_top_n_add, bm25_top_n_swap = get_bm25_plus_other_rel(bm25_top_n, labels, queries)\n","        padded_all_add, attention_mask_all_add, token_type_ids_all_add, temp_feedback_add = utils.bert_tokenizer(MODE, bm25_top_n_add, corpus,\n","                                                                                                                 labels, queries,\n","                                                                                                                 MAX_LENGTH, MODEL_TYPE)\n","\n","    # ========================================\n","    #               Folds\n","    # ========================================\n","    mrr_bm25_list, map_bm25_list, ndcg_bm25_list = [], [], []\n","    mrr_bert_list, map_bert_list, ndcg_bert_list = [], [], []\n","    mrr_bm25, map_bm25, ndcg_bm25 = 0, 0, 0\n","    mrr_bert, map_bert, ndcg_bert = 0, 0, 0\n","\n","    for fold_number in range(1, 6):\n","        print('======== Fold {:} / {:} ========'.format(fold_number, 5))\n","        train_index, test_index = data_utils.load_fold(fold_number)\n","\n","        padded, attention_mask, token_type_ids = [], [], []\n","        if MODE == 'Re-ranker':\n","            # no matter BM25_ENRICH-mode, next line required for test set construction\n","            padded, attention_mask, token_type_ids = padded_all, attention_mask_all, token_type_ids_all\n","            if BM25_ENRICH == 'swap':\n","                padded_swap, attention_mask_swap, token_type_ids_swap = padded_all_swap, attention_mask_all_swap, token_type_ids_all_swap\n","            elif BM25_ENRICH == 'add':\n","                padded_add, attention_mask_add, token_type_ids_add = padded_all_add, attention_mask_all_add, token_type_ids_all_add\n","            \n","        else:\n","            temp_feedback = []\n","            for query_num in range(0, len(bm25_top_n)):\n","                if query_num in test_index:\n","                    doc_nums = range(0, 1400)\n","                else:\n","                    doc_nums = bm25_top_n[query_num]\n","                padded.append(list(itemgetter(*doc_nums)(padded_all[query_num])))\n","                attention_mask.append(list(itemgetter(*doc_nums)(attention_mask_all[query_num])))\n","                token_type_ids.append(list(itemgetter(*doc_nums)(token_type_ids_all[query_num])))\n","                temp_feedback.append(list(itemgetter(*doc_nums)(labels[query_num])))\n","\n","        # Enricht the training set (or keep default)\n","        if BM25_ENRICH == 'default':\n","            train_dataset = data_utils.get_tensor_dataset(train_index, padded, attention_mask, token_type_ids,\n","                                                          temp_feedback)\n","        elif BM25_ENRICH == 'swap':\n","            train_dataset = data_utils.get_tensor_dataset(train_index, padded_swap, attention_mask_swap, token_type_ids_swap,\n","                                                    temp_feedback_swap)\n","        elif BM25_ENRICH == 'add':\n","            train_dataset = data_utils.get_tensor_dataset(train_index, padded_add, attention_mask_add, token_type_ids_add,\n","                                                    temp_feedback_add)\n","\n","        test_dataset = data_utils.get_tensor_dataset(test_index, padded, attention_mask, token_type_ids, temp_feedback)\n","\n","        mrr_bm25, map_bm25, ndcg_bm25, mrr_bm25_list, map_bm25_list, ndcg_bm25_list = utils.get_bm25_results(\n","            mrr_bm25_list, map_bm25_list, ndcg_bm25_list, test_index, tokenized_queries, bm25, mrr_bm25, map_bm25,\n","            ndcg_bm25, rel_fed, fold_number, MAP_CUT, NDCG_CUT)\n","\n","          \n","        # Option to load a custom trained model (used in transfer learning)\n","        if LOAD_CUSTOM_TRAINED_MODEL:\n","          model = load_specific_encoder(custom_model_path)\n","        else:\n","          model = None\n","          # with None the model_preparation loads the 'MODEL_TYPE' model\n","        if MULTI_LABEL:\n","          num_labels = 5\n","        else:\n","          num_labels = 2\n","        train_dataloader, test_dataloader, model, optimizer, scheduler = utils.model_preparation(MODEL_TYPE, train_dataset,\n","                                                                                                 test_dataset,\n","                                                                                                 BATCH_SIZE, TEST_BATCH_SIZE,\n","                                                                                                 LEARNING_RATE, EPOCHS, model=model,\n","                                                                                                 num_labels=num_labels,\n","                                                                                                 custom_model=CUSTOM_MODEL)\n","\n","\n","        # ========================================\n","        #               Training Loop\n","        # ========================================\n","        epochs_train_loss, epochs_val_loss = [], []\n","        for epoch_i in range(0, EPOCHS):\n","            # ========================================\n","            #               Training\n","            # ========================================\n","            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n","            print('Training...')\n","            model, optimizer, scheduler = utils.training(model, train_dataloader, device, optimizer, scheduler)\n","        # ========================================\n","        #               Testing\n","        # ========================================\n","        print('Testing...')\n","        mrr_bert, map_bert, ndcg_bert, mrr_bert_list, map_bert_list, ndcg_bert_list = utils.testing(MODE, model,\n","                                                                                                    test_dataloader,\n","                                                                                                    device, test_index,\n","                                                                                                    bm25_top_n,\n","                                                                                                    mrr_bert_list,\n","                                                                                                    map_bert_list,\n","                                                                                                    ndcg_bert_list,\n","                                                                                                    mrr_bert, map_bert,\n","                                                                                                    ndcg_bert, rel_fed,\n","                                                                                                    fold_number,\n","                                                                                                    MAP_CUT, NDCG_CUT,\n","                                                                                                    multilabel=MULTI_LABEL,\n","                                                                                                    argmax_sorting=ARG_MAX_SORTING,\n","                                                                                                    per_label_testing=PER_LABEL_TESTING)\n","    print(\"  BM25 MRR:  \" + \"{:.4f}\".format(mrr_bm25 / 5))\n","    print(\"  BM25 MAP:  \" + \"{:.4f}\".format(map_bm25 / 5))\n","    print(\"  BM25 NDCG: \" + \"{:.4f}\".format(ndcg_bm25 / 5))\n","\n","    print(\"  BERT MRR:  \" + \"{:.4f}\".format(mrr_bert / 5))\n","    print(\"  BERT MAP:  \" + \"{:.4f}\".format(map_bert / 5))\n","    print(\"  BERT NDCG: \" + \"{:.4f}\".format(ndcg_bert / 5))\n","\n","    utils.t_test(mrr_bm25_list, mrr_bert_list, 'MRR')\n","    utils.t_test(map_bm25_list, map_bert_list, 'MAP')\n","    utils.t_test(ndcg_bm25_list, ndcg_bert_list, 'NDCG')\n","    \n","    stop = timeit.default_timer()\n","    wall_time = (stop - start) / 60 \n","\n","    print('Time: ', wall_time, ' min') \n","\n","    # utils.results_to_csv('./mrr_bm25_list.csv', mrr_bm25_list)\n","    # utils.results_to_csv('./mrr_bert_list.csv', mrr_bert_list)\n","    # utils.results_to_csv('./map_bm25_list.csv', map_bm25_list)\n","    # utils.results_to_csv('./map_bert_list.csv', map_bert_list)\n","    # utils.results_to_csv('./ndcg_bm25_list.csv', ndcg_bm25_list)\n","    # utils.results_to_csv('./ndcg_bert_list.csv', ndcg_bert_list)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"b-DEy5MapwMc","executionInfo":{"status":"error","timestamp":1632839367123,"user_tz":-120,"elapsed":220394,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}},"outputId":"6137042b-9db6-4843-9661-63722b110776"},"source":["train_test()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["# ========================================\n","#               Hyper-Parameters\n","Re-ranker\n","bert-base-uncased\n","2e-05\n","128\n","32\n","1\n","# ========================================\n","#               Experiment-Settings\n","BM25_ENRICHMENT:    default\n","MULTI_LABEL:        True\n","ARGMAX-SORTING:     True\n","PER_LABEL_TESTING:  False\n","CUSTOM_MODEL:       weighted-BCEWIthLogitsLoss\n","# ========================================\n","#               Other\n","Tesla K80\n","# ========================================\n","GPU Type: Tesla K80\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n","  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["======== Fold 1 / 5 ========\n","MRR:  0.7837\n","MAP:  0.3493\n","NDCG: 0.5011\n","45\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultilabelSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForMultilabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMultilabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForMultilabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["======== Epoch 1 / 1 ========\n","Training...\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n","custom model, with loss type:  weighted-BCEWIthLogitsLoss\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-d3404dd34747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-c2f0ea88ac62>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'======== Epoch {:} / {:} ========'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;31m# ========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m#               Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/COMPUTING SCIENCE/THESIS_PROJECT/BERT-BM25-Thesis-Project/bert-meets-cranfield-multilabel/Code/utils.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, train_dataloader, device, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    363\u001b[0m                              \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                              \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                              labels=b_labels)\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/COMPUTING SCIENCE/THESIS_PROJECT/BERT-BM25-Thesis-Project/bert-meets-cranfield-multilabel/Code/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;31m# loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'weighted-BCEWIthLogitsLoss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mpos_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#  values in report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mone_hot_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Dw0zc0zqsxzr","executionInfo":{"status":"aborted","timestamp":1632839367121,"user_tz":-120,"elapsed":8,"user":{"displayName":"Maurice Verbrugge","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgqmdBO0giQPluidHjemi6aWvts_C_AZ5rqt1Y4yA=s64","userId":"18106956806494538064"}}},"source":[""],"execution_count":null,"outputs":[]}]}